{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6eea5e6-dbff-489e-8233-1fffbb44f1e6",
   "metadata": {},
   "source": [
    "# POSTTEST 7 Praktikum Kercedasan Buatan\n",
    "---\n",
    "(*2109106063* - Zahra Salsabila - B121)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f29d5-3857-4c80-990b-90cbfbbbeadc",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03882872-89fd-4005-b5ca-953046d9bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86b076-166e-4aad-9c4b-058ca232aa19",
   "metadata": {},
   "source": [
    "# Menampilkan Sample Data Gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8420cf-908e-49bf-891c-b374e686a726",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Edelweis/Train\\\\Anaphalis_Javanica\\\\Anaphalis_Javanica_0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# mengambil sample data gambar dari folder train\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     nama_gambar \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEdelweis/Train\u001b[39m\u001b[38;5;124m'\u001b[39m, class_name[i], class_name[i]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_0.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     gambar \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnama_gambar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\venv_B1-21\\Zahra_063\\lib\\site-packages\\matplotlib\\pyplot.py:2111\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2109\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(fname, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 2111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\venv_B1-21\\Zahra_063\\lib\\site-packages\\matplotlib\\image.py:1541\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1535\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1540\u001b[0m         )\n\u001b[1;32m-> 1541\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m   1542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1543\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32m~\\venv_B1-21\\Zahra_063\\lib\\site-packages\\PIL\\ImageFile.py:105\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[1;34m(self, fp, filename)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodermaxblock \u001b[38;5;241m=\u001b[39m MAXBLOCK\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Edelweis/Train\\\\Anaphalis_Javanica\\\\Anaphalis_Javanica_0.png'"
     ]
    }
   ],
   "source": [
    "class_name = ['Anaphalis_Javanica', 'Leontopodium_Alpinum', 'Leucogenes_Grandiceps']\n",
    "\n",
    "for i in range(3):\n",
    "    # mengambil sample data gambar dari folder train\n",
    "    nama_gambar = os.path.join('Edelweis/Train', class_name[i], class_name[i]+'_0.png')\n",
    "    gambar = plt.imread(nama_gambar)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(gambar)\n",
    "    plt.xlabel(class_name[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e872eb6-ac00-4e1f-83f3-e5e036d2814b",
   "metadata": {},
   "source": [
    "# Preprocessing Data Gambar (Augmentasi Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ac071-945f-4630-9cfe-a998253dcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.1,\n",
    "    rotation_range=5,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True, \n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf0f7a-7c70-4af0-b9e9-b324f4bcd2a4",
   "metadata": {},
   "source": [
    "# Split Data Menjadi train,val dan test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045199ad-decd-460c-bedd-af2590ceff60",
   "metadata": {},
   "source": [
    "- File directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032927b0-a4bc-409f-96a5-8a88651e8e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Train'\n",
    "test_dir = 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53f3bc-7e33-4e7d-9d94-5e394dfce405",
   "metadata": {},
   "source": [
    "- Split dataset ke dalam train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1691d-6a6f-4666-a864-b5d5db897c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = img_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ed9c0-2ace-4580-b275-018a4b1a9430",
   "metadata": {},
   "source": [
    "- Split dataset ke dalam validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2f1b7-b7be-40f9-a70d-51d829f7af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = img_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f69cd-7711-4fe8-8e76-55dbd0e8a58f",
   "metadata": {},
   "source": [
    "- Split dataset ke dalam test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b5aa6-45fc-4ec6-9935-3320afc8bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = img_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    seed=42,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874ce37-dec6-4f51-a2b3-8ddce01c2e78",
   "metadata": {},
   "source": [
    "# Membuat Model Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2512d-fe07-4a5d-8999-4253138a22a7",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf85ce-9e8b-4fb0-8a02-d87ece1edcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(128, 128, 3)),\n",
    "    Conv2D(16, (3,3), activation='relu' ),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(2048, activation='relu'),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1bd8c-8411-4123-8b1b-491dae01ca6c",
   "metadata": {},
   "source": [
    "- Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a889bde-b189-4e92-9905-35444e5201c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88332716-0de1-4a83-96b2-0d85518f9300",
   "metadata": {},
   "source": [
    "# Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028ce97-701a-4692-9431-26bdecdf1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b13b6-fe1a-4eb8-b64c-9835510e7dd4",
   "metadata": {},
   "source": [
    "# Fit Model\n",
    "- Fungsi callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c18ef-d170-424e-ac56-7f225a8b854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0, \n",
    "    mode='auto')\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5,\n",
    "    patience=5)\n",
    "\n",
    "callbacks = [early_stopping_callback, lr_reducer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6dd28-c310-4596-b6e7-c043ed1eb957",
   "metadata": {},
   "source": [
    "- Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390021f-219e-45e2-839f-d49251868d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(\n",
    "    train_gen,\n",
    "    epochs = 10,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3cac3b-d09e-43db-8283-ae747ce6ab74",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13439266-e5f2-4f55-b005-634e6cfcea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_gen)\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb250de0-146f-4761-ab44-2cd31b206b38",
   "metadata": {},
   "source": [
    "# Grafik Pergerakan Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd717b-2bf9-4b14-8416-49186e241250",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_fit.history['accuracy']\n",
    "val_acc = model_fit.history['val_accuracy']\n",
    "loss_ = model_fit.history['loss']\n",
    "val_loss_ = model_fit.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e6eee-3060-4294-a4d8-d9f9888ce44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecbbc7-e512-46f4-98ea-646e6a2eaae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Zahra_063",
   "language": "python",
   "name": "zahra_063"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
